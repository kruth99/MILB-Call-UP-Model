"0","#1)"
"0","set.seed(87329)"
"0",""
"0","#2)"
"0","x = rnorm(100, mean = 1, sd = 3)"
"0","y = rnorm(100, mean = 1, sd = 3)"
"0","test = t.test(x, y, alternative= ""two.sided"", var.equal = TRUE)"
"0","test$p.value"
"1","[1]"
"1"," 0.5903104"
"1","
"
"0","# The p value is equal to 0.5903 which is greater than the alpha value of 0.05. We fail to reject the null hypothesis, there is not a statistically significant difference between the population means of population X and Y"
"0",""
"0","#3)"
"0","par(ask=TRUE)"
"0","pvalue <- vector(length=10000)"
"0","for(i in 1:10000) {"
"0","    x = rnorm(100, mean = 1, sd = 3)"
"0","    y = rnorm(100, mean = 1, sd = 3)"
"0","    test = t.test(x, y, alternative= ""two.sided"", var.equal = TRUE)"
"0","    if (test$p.value > 0.05){"
"0","      pvalue[i] = FALSE"
"0","    }"
"0","    else {"
"0","      pvalue[i] = TRUE"
"0","    }"
"0","}"
"0","par(ask=FALSE)"
"0","print(sum(pvalue))"
"1","[1]"
"1"," 475"
"1","
"
"0","# It was rejected 475 times"
"0",""
"0","# The null hypothesis was rejected 475, which is about 4.75% of the time. This was approximately equal to 5% (alpha), but it is not exactly equal. In the case of multiple testing, as you increase n to a higher and higher number and you don't adjust alpha or the p-value, you'll get closer and closer to having 5% of the tests rejecting the null hypothesis. "
"0",""
"0","# About 0.0475 of the tests were rejected. This number is not exactly equal to 0.05 because there is a lot of variability in our testing. When you flip a coin 100 times, you will not get exactly 50 heads and 50 tails. It will be right around that number, but often it will be slightly off, because there is some random/chance error. "
"0",""
"0",""
