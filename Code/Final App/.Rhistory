headinj <- read.table("https://dahl.byu.edu/230/2022a/data/headinjury.csv",sep=",",header=TRUE)
head(headinj)
str(headinj)
hist(headinj$HeadInjury,breaks=15, main="Histogram of Head Injury Scores", xlab="Score")
boxplot(HeadInjury ~ Type, data=headinj)
headinj.fm <- aov(HeadInjury ~ Type, data=headinj)
summary(headinj.fm)
TukeyHSD(headinj.fm) # check whether CIs include 0
hist(residuals(headinj.fm))
#b) Ho: alpha1(compact) = alpha2(heavy) = alpha3(light) = alpha4(medium) = alpha5(minivan) = alpha6(pickup) = alpha7(van)
#Ha: At least one of the means is different
#1)
set.seed(87329)
#2)
x = rnorm(100, mean = 1, sd = 3)
y = rnorm(100, mean = 1, sd = 3)
test = t.test(x, y, alternative= "two.sided", var.equal = TRUE)
test$p.value
# The p value is equal to 0.5903 which is greater than the alpha value of 0.05. We fail to reject the null hypothesis, there is not a significant difference between the population means of population X and Y
#3)
par(ask=TRUE)
pvalue <- vector(length=10000)
for(i in 1:10000) {
x = rnorm(100, mean = 1, sd = 3)
y = rnorm(100, mean = 1, sd = 3)
test = t.test(x, y, alternative= "two.sided", var.equal = TRUE)
if (test$p.value > 0.05){
pvalue[i] = FALSE
}
else {
pvalue[i] = TRUE
}
}
par(ask=FALSE)
print(sum(pvalue))
# It was rejected 475 times
# The null hypothesis was rejected 475, which is about 4.75% of the time. This was approximately equal to 5% (alpha), but it is not exactly equal. In the case of multiple testing, as you increase n to a higher and higher number and you don't adjust alpha or the p-value, you'll get closer and closer to having 5% of the tests rejecting the null hypothesis.
# About 0.0475 of the tests were rejected. This number is not exactly equal to 0.05 because there is a lot of variability in our testing. When you flip a coin 100 times, you will not get exactly 50 heads and 50 tails. It will be right around that number, but often it will be slightly off, because there is some random/chance error.
#1)
set.seed(87329)
#2)
x = rnorm(100, mean = 1, sd = 3)
y = rnorm(100, mean = 1, sd = 3)
test = t.test(x, y, alternative= "two.sided", var.equal = TRUE)
test$p.value
# The p value is equal to 0.5903 which is greater than the alpha value of 0.05. We fail to reject the null hypothesis, there is not a significant difference between the population means of population X and Y
#3)
par(ask=TRUE)
pvalue <- vector(length=10000)
for(i in 1:10000) {
x = rnorm(100, mean = 1, sd = 3)
y = rnorm(100, mean = 1, sd = 3)
test = t.test(x, y, alternative= "two.sided", var.equal = TRUE)
if (test$p.value > 0.05){
pvalue[i] = FALSE
}
else {
pvalue[i] = TRUE
}
}
par(ask=FALSE)
print(sum(pvalue))
# It was rejected 475 times
# The null hypothesis was rejected 475, which is about 4.75% of the time. This was approximately equal to 5% (alpha), but it is not exactly equal. In the case of multiple testing, as you increase n to a higher and higher number and you don't adjust alpha or the p-value, you'll get closer and closer to having 5% of the tests rejecting the null hypothesis.
# About 0.0475 of the tests were rejected. This number is not exactly equal to 0.05 because there is a lot of variability in our testing. When you flip a coin 100 times, you will not get exactly 50 heads and 50 tails. It will be right around that number, but often it will be slightly off, because there is some random/chance error.
#1)
set.seed(87329)
#2)
x = rnorm(100, mean = 1, sd = 3)
y = rnorm(100, mean = 1, sd = 3)
test = t.test(x, y, alternative= "two.sided", var.equal = TRUE)
test$p.value
# The p value is equal to 0.5903 which is greater than the alpha value of 0.05. We fail to reject the null hypothesis, there is not a statistically significant difference between the population means of population X and Y
#3)
par(ask=TRUE)
pvalue <- vector(length=10000)
for(i in 1:10000) {
x = rnorm(100, mean = 1, sd = 3)
y = rnorm(100, mean = 1, sd = 3)
test = t.test(x, y, alternative= "two.sided", var.equal = TRUE)
if (test$p.value > 0.05){
pvalue[i] = FALSE
}
else {
pvalue[i] = TRUE
}
}
par(ask=FALSE)
print(sum(pvalue))
# It was rejected 475 times
# The null hypothesis was rejected 475, which is about 4.75% of the time. This was approximately equal to 5% (alpha), but it is not exactly equal. In the case of multiple testing, as you increase n to a higher and higher number and you don't adjust alpha or the p-value, you'll get closer and closer to having 5% of the tests rejecting the null hypothesis.
# About 0.0475 of the tests were rejected. This number is not exactly equal to 0.05 because there is a lot of variability in our testing. When you flip a coin 100 times, you will not get exactly 50 heads and 50 tails. It will be right around that number, but often it will be slightly off, because there is some random/chance error.
pnorm(0.714, mean = 0, sd = 1, lower.tail = TRUE)
pnorm(0.714, mean = 1.5, sd = 2.1, lower.tail = TRUE)
pnorm(-0.714, mean = 1.5, sd = 2.1, lower.tail = TRUE)
pnorm(-0.714, mean = 1.5, sd = 2.1)
pnorm(-0.714, mean = 1.5, sd = 2.1, lower.tail = FALSE)
1-0.761
pnorm(q = 0.714, lower.tail = FALSE)
pnorm(q = 0.71, lower.tail = FALSE)
0.9/2.1
pnorm(0.4)
pnorm(0.6, lower.tail = TRUE)
qnorm(0.6, lower.tail = TRUE)
qnorm(0.4\)
qnorm(0.4)
0.2533471*2.1
0.2533471*2.1/1.5
(0.2533471*2.1)/1.5
(-0.2533471*2.1)/1.5
(-0.2533471*2.1)-1.5
(0.2533471*2.1)-1.5
-(0.2533471*2.1)+1.5
-(0.2533471*2.1)
1.5 - (0.2533471*2.1)
1.5 - (0.2533471*2.1)
ans + 1
(2.1*0.2533471)+1.5
5-4/(1.2/3)
(5-4)/(1.2/3)
?qnorm
?pt
?qt
pt(2.5, 8, lower.tail=FALSE)
pt(2.5, 8)
qt(2.5,8)
?pnorm
pnorm(2.5)
pnorm(2.5,lower.tail=FALSE)
?pt
pnorm(0.05)
qnorm(0.05)
qnorm(0.05, lower.tail=FALSE)
d <- read.csv("helicopter.csv")
names(d)
# Convert 'netid' and 'id' from numeric variables to factors.
d$id <- as.factor(d$id)
d$netid <- as.factor(d$netid)
#B
# Exploratory data analysis
x1 <- aggregate(time ~ body, data=d, FUN=mean)
x2 <- aggregate(time ~ wing, data=d, FUN=mean)
x3 <- aggregate(time ~ body*wing, data=d, FUN=mean)
x1
x2
x3
#C
# Different ways to compute the grand mean estimate
mean(x1$time)
mean(x2$time)
mean(x3$time)
mean(d$time)   # This last one only works because the design is balanced.
# Main effect of Body
1.452473- mean(x1$time)
1.436165- mean(x1$time)
# +/- 0.008154004
# 0.008154004 for small body
# -0.008154004 for large body
# Mean effect of wings
1.653011 - mean(x1$time)
#0.208692 for large wings
1.410054- mean(x1$time)
#-0.034265 for medium wings
1.269892	- mean(x1$time)
#-0.174427 for small wings
# L body L Wing
1.656559	- (-0.008154004) - mean(x1$time) - 0.208692
#0.01170201
# S body L Wing
1.649462	- 0.008154004 - mean(x1$time) - 0.208692
#-0.011703
# L body M wing
1.397419	- (-0.008154004) - mean(x1$time) - (-0.034265)
#-0.004480992
# S body M wing
1.422688 - 0.008154004 - mean(x1$time) - (-0.034265)
#0.00448
# L body S wing
1.254516 - (-0.008154004) - mean(x1$time) - (-0.174427)
#-0.007221992
# S body S wing
1.285269 - 0.008154004 - mean(x1$time) - (-0.174427)
#0.007223
# Estimates of the effects are probably easiest to compute 'by hand'.
#E) ANOVA with two-way interaction.
fm <- lm(time ~ body*wing, data=d)
anova(fm)
#F) Interaction plots.
interaction.plot(d$wing,d$body,d$time)
interaction.plot(d$body,d$wing,d$time)
#########
### Check assumptions
#########
boxplot(time ~ body*wing, data=d)  # Note the ordering of the x axis.
boxplot(time ~ id, data=d)         # Note the ordering of the x axis.
# Normality assumption looks borderline but, coupled with the Central Limit Theorem, we should be okay.
hist(residuals(fm))
# Constant standard deviation assumption looks okay.
# Notice that the ratio of standard deviations is aways between 0.5 and 2.
aggregate(time ~ body*wing, data=d, FUN=sd)
5.6 + c(-1,1) *(qt(0.005, df=16, lower.tail=FALSE) * 8.6/sqrt(17))
pnorm(0.714)
pnorm(0.714, lower.tail=FALSE)
shiny::runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
shiny::runApp()
runApp()
shiny::runApp()
shiny::runApp()
runApp()
choose(16,6)
choose(5,2)*choose(11,4)
choose(5,2)*choose(11,4) + choose(5,3)*choose(11,3) + choose(5,4)*choose(11,2) + choose(5,5)*choose(11,1)
3300/8008
5236/8008
choose(5,2)
perm <- function(n,k) choose(n,k)*factorial(k)
perm(5,2)
perm(3,3)
perm(2,2)
choose(2,1)
choose(3,3)
0!
choose(5,2)
(3 choose 1)* (6 choose 2) * (9 choose 1)
choose(3,1) * choose(6,2) * choose(9,1)
405/choose(15,3)
choose(6,2)* choose(9,1)/choose(15,3)
choose(4,3) + choose(5,3) + choose(6,3)/choose(15,3)
(choose(4,3) + choose(5,3) + choose(6,3))/choose(15,3)
(choose(4,3) + choose(5,3) + choose(6,3))/choose(15,3)
(choose(4,3) + choose(5,3) + choose(6,3))/choose(15,3)
(choose(3,1)* choose(4,1) * choose(2,1) * choose(5,1) * 1 * choose(6,1)/choose(15,3)
(choose(3,1)* choose(4,1) * choose(2,1) * choose(5,1) * 1 * choose(6,1))/choose(15,3)
(choose(3,1)* choose(4,1) * choose(2,1) * choose(5,1) * 1 * choose(6,1))/choose(15,3)
(choose(3,1)* choose(4,1) * choose(2,1) * choose(5,1) * 1 * choose(6,1))/choose(15,3)
(choose(4,1) * choose(5,1) * choose(6,1))/choose(15,3)
(choose(6,1)/choose(15,4)
(choose(6,1)/choose(15,4)
#2
f <- function(x) 3*x+7
curve(f(x), xlim=c(-1,1))
#3
f <- function(x) 1 - e**(-0.2 * x)
curve(f(x), xlim=c(0,20))
#3
f <- function(x) 1 - exp(-0.2 * x)
curve(f(x), xlim=c(0,20))
#4
f <- function(x) (3/4) * (1 - x**2)
curve(f(x), xlim=c(-1,1))
#5
f <- function (exp(2 * x) / (1 + exp( 2* x)))
#5
f <- function exp(2 * x) / (1 + exp( 2* x))
#5
f <- function(x) (exp)(2 * x)) / (1 + exp( 2* x))
#5
f <- function(x) ((exp)(2 * x)) / (1 + exp( 2* x)))
#5
f <- function(x) ((exp (2 * x)) / (1 + exp( 2* x))
curve(f(x), xlim=c(0,20))
#5
f <- function(x) (exp (2 * x)) / (1 + exp( 2* x))
curve(f(x), xlim=c(0,20))
#5
f <- function(x) (exp (2 * x)) / (1 + exp( 2* x))
curve(f(x), xlim=c(-3,3))
#6
f <- function(x) sin(12(x + 0.2)) / (x + 0.2)
curve(f(x), xlim=c(0,1))
#6
f <- function(x) sin (12 * (x + 0.2)) / (x + 0.2)
curve(f(x), xlim=c(0,1))
